{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88079a16",
   "metadata": {},
   "source": [
    "# Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ae079",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8d156",
   "metadata": {},
   "source": [
    "### Install a Local LLM with Ollama\n",
    "\n",
    "To run this project locally, we will install and use **Ollama**, a lightweight runtime for local large language models.\n",
    "\n",
    "**Download Ollama:**  \n",
    "https://ollama.com/\n",
    "\n",
    "Once installed, you can pull any model you want to run.  \n",
    "Below are a few recommended examples, but you are free to pick any size or model from the Ollama library.\n",
    "\n",
    "ollama pull qwen3:0.6b\n",
    "\n",
    "or\n",
    "\n",
    "ollama pull ibm/granite4:350m\n",
    "\n",
    "or\n",
    "\n",
    "Choose any model you prefer, make sure the model supports tools.\n",
    "Browse available models here:\n",
    "https://ollama.com/library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42933887",
   "metadata": {},
   "source": [
    "### Python requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e73d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langgraph langchain-google-genai langchain-core mcp langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e2139",
   "metadata": {},
   "source": [
    "## 1. Define FastMCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad28890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristics import *\n",
    "from color_blocks_state import *\n",
    "from search import *\n",
    "import asyncio\n",
    "from langchain_core.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f2c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "\n",
    "def normalize_start_blocks_any(x: Any) -> str:\n",
    "    \"\"\"\n",
    "    Returns canonical \"(a,b),(c,d),...\" string.\n",
    "    Accepts:\n",
    "      - str: \"(5,2),(1,3)...\"\n",
    "      - list[str] chunks\n",
    "      - list[tuple[int,int]] or tuple[tuple[int,int],...]\n",
    "    \"\"\"\n",
    "    # tuple/list of pairs -> convert directly\n",
    "    if isinstance(x, (list, tuple)) and x and all(isinstance(t, (list, tuple)) and len(t) == 2 for t in x):\n",
    "        pairs = [f\"({int(a)},{int(b)})\" for a, b in x]\n",
    "        return \",\".join(pairs)\n",
    "\n",
    "    # list of strings -> join\n",
    "    if isinstance(x, list):\n",
    "        s = \",\".join(str(p) for p in x)\n",
    "    else:\n",
    "        s = str(x)\n",
    "\n",
    "    s = s.strip().lstrip(\"/\").strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    # extract (d,d) pairs\n",
    "    pairs = re.findall(r\"\\(\\s*\\d+\\s*,\\s*\\d+\\s*\\)\", s)\n",
    "    if not pairs:\n",
    "        raise ValueError(f\"start_blocks invalid: expected '(a,b),(c,d),...' got {x!r}\")\n",
    "    return \",\".join(p.replace(\" \", \"\") for p in pairs)\n",
    "\n",
    "\n",
    "def normalize_goal_blocks_any(x: Any) -> str:\n",
    "    \"\"\"\n",
    "    Normalize goal_blocks into canonical \"a,b,c,...\" string.\n",
    "\n",
    "    Accepts artifacts like:\n",
    "      - \"/10,2,3,4\"\n",
    "      - \"/2,/4,/6,/8\"   <-- per-token slashes\n",
    "      - quotes, spaces\n",
    "      - list/tuple of ints/strings\n",
    "    \"\"\"\n",
    "    # list/tuple of ints or digit-strings -> join\n",
    "    if isinstance(x, (list, tuple)) and x and all(\n",
    "        isinstance(v, int) or (isinstance(v, str) and v.strip().lstrip(\"/\").isdigit())\n",
    "        for v in x\n",
    "    ):\n",
    "        return \",\".join(str(int(str(v).strip().lstrip(\"/\"))) for v in x)\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # strip wrappers/quotes\n",
    "    s = s.strip('\"').strip(\"'\")\n",
    "    s = s.replace(\" \", \"\")\n",
    "\n",
    "    # If it looks like weird nested tuples, reject clearly\n",
    "    if s.startswith(\"[(\") or s.startswith(\"((\"):\n",
    "        raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "\n",
    "    # split by comma, strip leading '/' from EACH token\n",
    "    tokens = [t for t in s.split(\",\") if t != \"\"]\n",
    "    cleaned = []\n",
    "    for t in tokens:\n",
    "        t2 = t.strip().lstrip(\"/\")   # <-- key fix\n",
    "        if not t2.isdigit():\n",
    "            raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "        cleaned.append(t2)\n",
    "\n",
    "    if not cleaned:\n",
    "        raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "\n",
    "    return \",\".join(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea6d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ColorBlocksArgs(BaseModel):\n",
    "    start_blocks: str = Field(..., description='EXACT \"(a,b),(c,d),...\" no spaces')\n",
    "    goal_blocks: str  = Field(..., description='EXACT \"g0,g1,g2,...\" no spaces')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3eeb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.server.fastmcp import FastMCP\n",
    "import math\n",
    "\n",
    "# Initialize FastMCP\n",
    "mcp = FastMCP(\"Unified Solver\")\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_sum(a: float, b: float) -> float:\n",
    "    \"\"\"Calculates the sum of two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Calculates the power of a base number.\"\"\"\n",
    "    return math.pow(base, exponent)\n",
    "\n",
    "# TO DO: Add more tools as needed for your application\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def solve_cost_mcp(start_blocks, goal_blocks) -> float:\n",
    "    \"\"\"\n",
    "    Compute the optimal solution cost for the Color Blocks search problem.\n",
    "\n",
    "    INPUTS (MUST be single values, not nested objects):\n",
    "    - start_blocks: string \"(a,b),(c,d),...\"  (each block is a pair top,bottom)\n",
    "    - goal_blocks:  string \"g0,g1,g2,...\" (top colors required at each position)\n",
    "\n",
    "    OUTPUT:\n",
    "    - A single number (float): optimal path cost (each move costs 1).\n",
    "    \"\"\"\n",
    "    start_blocks = normalize_start_blocks_any(start_blocks)\n",
    "    goal_blocks  = normalize_goal_blocks_any(goal_blocks)\n",
    "\n",
    "    init_goal_for_heuristics(goal_blocks)\n",
    "    init_goal_for_search(goal_blocks)\n",
    "    start_state = color_blocks_state(blocks_str=start_blocks)\n",
    "    path = search(start_state, advanced_heuristic)\n",
    "    return float(\"inf\") if path is None else float(path[-1].g)\n",
    "\n",
    "def solve_cost_wrapper(args: ColorBlocksArgs) -> float:\n",
    "    return solve_cost_mcp(args.start_blocks, args.goal_blocks)\n",
    "\n",
    "\n",
    "def as_langchain_tool_from_fn(fn, name: str, description: str, args_schema=None):\n",
    "    return StructuredTool.from_function(\n",
    "        func=fn,\n",
    "        name=name,\n",
    "        description=description,\n",
    "        args_schema=args_schema,\n",
    "        coroutine=fn if asyncio.iscoroutinefunction(fn) else None,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "solve_cost_tool = as_langchain_tool_from_fn(\n",
    "    solve_cost_wrapper,\n",
    "    name=\"solve_color_blocks_cost\",\n",
    "    description=(\n",
    "        \"Compute optimal solution cost for Color Blocks.\\n\"\n",
    "        \"REQUIRES BOTH: start_blocks and goal_blocks.\\n\"\n",
    "        \"Returns a single float cost.\"\n",
    "    ),\n",
    "    args_schema=ColorBlocksArgs\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32e06d",
   "metadata": {},
   "source": [
    "## 2. LLM + MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e9ea7",
   "metadata": {},
   "source": [
    "### 2.1. Global instance of our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420c2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# Choose your model here, can be Ollama or Google Gemini\n",
    "# Can also switch between different model sizes as needed\n",
    "model = \"qwen3:0.6b\"\n",
    "model = \"ibm/granite4:350m\"\n",
    "global_llm = ChatOllama(model=model, temperature=0.0)\n",
    "\n",
    "\n",
    "# SETUP API KEY if using Google Gemini\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY_HERE\"\n",
    "\n",
    "# model = \"gemini-2.5-flash\"\n",
    "# model = \"gemini-2.5-flash-lite\"\n",
    "# global_llm = ChatGoogleGenerativeAI(model=model, temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d5dee",
   "metadata": {},
   "source": [
    "### 2.2. Our agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dba39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver # Optional: For saving graph state\n",
    "\n",
    "\n",
    "def create_agent_graph(sys_msg, tools):\n",
    "    \"\"\" Creates a LangGraph StateGraph with the given tools integrated.\"\"\"\n",
    "\n",
    "    llm = global_llm\n",
    "\n",
    "    if tools:\n",
    "        llm_with_tools = llm.bind_tools(tools)\n",
    "    else:\n",
    "        llm_with_tools = llm\n",
    "\n",
    "    # Node\n",
    "    def assistant(state: MessagesState):\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                llm_with_tools.invoke([sys_msg] + state[\"messages\"], think=False)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Graph\n",
    "    builder = StateGraph(MessagesState)\n",
    "\n",
    "    # Define the basic graph structure\n",
    "    builder.add_node(\"assistant\", assistant)\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "\n",
    "    if tools:\n",
    "        builder.add_node(\"tools\", ToolNode(tools))  \n",
    "        builder.add_conditional_edges(\n",
    "            \"assistant\",\n",
    "            tools_condition,\n",
    "        )\n",
    "        builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    react_graph = builder.compile()\n",
    "\n",
    "    return react_graph\n",
    "\n",
    "\n",
    "async def run_agent(prompt, tools, sys_msg=\"\"):\n",
    "\n",
    "    sys_msg = SystemMessage(content=sys_msg)\n",
    "\n",
    "    # 3. Create Graph\n",
    "    graph = create_agent_graph(sys_msg, tools)\n",
    "    \n",
    "    # 4. Run (using ainvoke for async tools)\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    result = await graph.ainvoke({\"messages\": [HumanMessage(content=prompt)]}, config)\n",
    "\n",
    "    last_msg = result[\"messages\"][-1].content\n",
    "\n",
    "    # Extract tool names and outputs\n",
    "    tools_used = []\n",
    "    tools_output = []\n",
    "    \n",
    "    # Parsing logic specific to your request\n",
    "    for msg in result[\"messages\"]:\n",
    "        # In LangChain, tool calls are usually in 'tool_calls' attribute of AIMessage\n",
    "        # or 'name' attribute if it is a ToolMessage\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "             for tool_call in msg.tool_calls:\n",
    "                tools_used.append(tool_call['name'])\n",
    "        \n",
    "        if msg.type == 'tool':\n",
    "            tools_output.append(msg.content)\n",
    "\n",
    "    return last_msg, tools_used, tools_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73790d1f",
   "metadata": {},
   "source": [
    "### 2.3. Tools that run spacific agent (with tools and without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6678099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "import asyncio\n",
    "\n",
    "WITH_TOOLS_SYS = \"\"\"\n",
    "You are the WITH-TOOLS assistant.\n",
    "\n",
    "You MUST call the tool solve_cost_mcp EXACTLY ONCE using the given arguments.\n",
    "\n",
    "Input format (use EXACTLY as provided):\n",
    "- start_blocks: a single string in the format \"(a,b),(c,d),...\"\n",
    "- goal_blocks: a single string in the format \"x,y,z,...\"\n",
    "\n",
    "Rules:\n",
    "- Do NOT add or remove characters.\n",
    "- Do NOT add leading symbols (/, [, ], quotes).\n",
    "- Do NOT split start_blocks into a list.\n",
    "- Do NOT change the order of blocks.\n",
    "\n",
    "After the tool returns:\n",
    "- Output ONLY the numeric solution cost.\n",
    "- Do NOT include explanations or extra text.\n",
    "\"\"\"\n",
    "\n",
    "NO_TOOLS_SYS = \"\"\"\n",
    "You are the NO-TOOLS assistant.\n",
    "\n",
    "You are solving a SEARCH problem WITHOUT tools and WITHOUT running code.\n",
    "You must still produce an answer.\n",
    "\n",
    "Domain rules:\n",
    "- State is a list of pairs (top,bottom).\n",
    "- spin(i): swaps top and bottom of block i. Cost = 1.\n",
    "- flip(i): reverses the order of blocks from index i to the end. Cost = 1.\n",
    "- Goal: for each position i, the top color equals goal_blocks[i].\n",
    "\n",
    "Instructions:\n",
    "- Reason mentally using the rules above.\n",
    "- If unsure, prefer a CONSERVATIVE estimate (slightly higher, not lower).\n",
    "- Never refuse and never ask for more information.\n",
    "\n",
    "Output:\n",
    "Output:\n",
    "- Output ONLY a single number.\n",
    "- NO explanation, NO steps, NO extra text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_with_tools(start_blocks: str, goal_blocks: str) -> str:\n",
    "    \"\"\"\n",
    "    WITH-TOOLS assistant.\n",
    "    Must call solve_cost_mcp exactly once and return ONLY the numeric cost.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_msg = f\"\"\"{WITH_TOOLS_SYS}\n",
    "\n",
    "Use these exact inputs:\n",
    "start_blocks = \"{start_blocks}\"\n",
    "goal_blocks  = \"{goal_blocks}\"\n",
    "\"\"\"\n",
    "    # Only the solver tool is available\n",
    "    tools = [solve_cost_mcp]\n",
    "\n",
    "    last_msg, _, _ = await run_agent(\n",
    "        prompt=\"Compute the solution cost.\",\n",
    "        tools=tools,\n",
    "        sys_msg=sys_msg\n",
    "    )\n",
    "\n",
    "    return last_msg\n",
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_without_tools(start_blocks: str, goal_blocks: str) -> str:\n",
    "    \"\"\"\n",
    "    NO-TOOLS assistant.\n",
    "    Must estimate and return ONLY a numeric cost.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_msg = f\"\"\"{NO_TOOLS_SYS}\n",
    "\n",
    "Start blocks: {start_blocks}\n",
    "Goal blocks: {goal_blocks}\n",
    "\"\"\"\n",
    "\n",
    "    last_msg, _, _ = await run_agent(\n",
    "        prompt=\"Estimate the minimal solution cost. Output only a number.\",\n",
    "        tools=[],\n",
    "        sys_msg=sys_msg\n",
    "    )\n",
    "\n",
    "    return last_msg\n",
    "\n",
    "\n",
    "def as_langchain_tool_from_fn(fn, name: str, description: str, args_schema):\n",
    "    return StructuredTool.from_function(\n",
    "        func=fn,\n",
    "        name=name,\n",
    "        description=description,\n",
    "        args_schema=args_schema,\n",
    "        coroutine=fn if asyncio.iscoroutinefunction(fn) else None,\n",
    "    )\n",
    "\n",
    "\n",
    "async def ask_with_tools_wrapper(\n",
    "    start_blocks: str = None,\n",
    "    goal_blocks: str = None,\n",
    "    args: ColorBlocksArgs = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    if args is not None:\n",
    "        start_blocks = start_blocks or args.start_blocks\n",
    "        goal_blocks = goal_blocks or args.goal_blocks\n",
    "\n",
    "    if start_blocks is None or goal_blocks is None:\n",
    "        raise ValueError(f\"Missing args: start_blocks={start_blocks}, goal_blocks={goal_blocks}\")\n",
    "\n",
    "    return await ask_agent_with_tools(start_blocks, goal_blocks)\n",
    "\n",
    "\n",
    "async def ask_without_tools_wrapper(\n",
    "    start_blocks: str = None,\n",
    "    goal_blocks: str = None,\n",
    "    args: ColorBlocksArgs = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    if args is not None:\n",
    "        start_blocks = start_blocks or args.start_blocks\n",
    "        goal_blocks = goal_blocks or args.goal_blocks\n",
    "\n",
    "    if start_blocks is None or goal_blocks is None:\n",
    "        raise ValueError(f\"Missing args: start_blocks={start_blocks}, goal_blocks={goal_blocks}\")\n",
    "\n",
    "    return await ask_agent_without_tools(start_blocks, goal_blocks)\n",
    "\n",
    "\n",
    "ask_with_tools_tool = as_langchain_tool_from_fn(\n",
    "    ask_with_tools_wrapper,\n",
    "    name=\"ask_agent_with_tools\",\n",
    "    description=(\n",
    "        \"Calls the WITH-TOOLS assistant.\\n\"\n",
    "        \"REQUIRES BOTH start_blocks and goal_blocks.\\n\"\n",
    "        \"Returns ONLY a numeric cost as a string.\"\n",
    "    ),\n",
    "    args_schema=ColorBlocksArgs\n",
    ")\n",
    "\n",
    "ask_without_tools_tool = as_langchain_tool_from_fn(\n",
    "    ask_without_tools_wrapper,\n",
    "    name=\"ask_agent_without_tools\",\n",
    "    description=(\n",
    "        \"Calls the NO-TOOLS assistant.\\n\"\n",
    "        \"REQUIRES BOTH start_blocks and goal_blocks.\\n\"\n",
    "        \"Returns ONLY a numeric cost as a string.\"\n",
    "    ),\n",
    "    args_schema=ColorBlocksArgs\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f6ab0",
   "metadata": {},
   "source": [
    "## 3. Run the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1ebf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= CASE 1 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESPONSE ===\n",
      "The WITH-TOOLS solution cost is 6.0.\n",
      "The NO-TOOLS solution cost is 1.\n",
      "=== TOOLS USED ===\n",
      "['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "=== TOOL OUTPUTS ===\n",
      "['The optimal solution cost is 6.0.', '1']\n",
      "\n",
      "================= CASE 2 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESPONSE ===\n",
      "The WITH-TOOLS solution cost is 1.0. The NO-TOOLS solution also costs 1.0. Both approaches yield the same optimal cost of 1.0.\n",
      "=== TOOLS USED ===\n",
      "['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "=== TOOL OUTPUTS ===\n",
      "['The optimal solution cost is 1.0.', '1']\n",
      "\n",
      "================= CASE 3 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESPONSE ===\n",
      "The WITH-TOOLS solution cost is 4.0.\n",
      "The NO-TOOLS solution cost is 1.0.\n",
      "=== TOOLS USED ===\n",
      "['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "=== TOOL OUTPUTS ===\n",
      "['The solution cost is 4.0.', '1']\n",
      "\n",
      "================= CASE 4 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESPONSE ===\n",
      "The WITH-TOOLS solution cost is 3.0.\n",
      "The NO-TOOLS solution cost is 1.0.\n",
      "=== TOOLS USED ===\n",
      "['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "=== TOOL OUTPUTS ===\n",
      "['The optimal solution cost is 3.0.', '1']\n",
      "\n",
      "================= CASE 5 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESPONSE ===\n",
      "The WITH-TOOLS solution cost is 4.0.\n",
      "The NO-TOOLS solution cost is 1.\n",
      "=== TOOLS USED ===\n",
      "['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "=== TOOL OUTPUTS ===\n",
      "['The solution cost is 4.0.', '1']\n"
     ]
    }
   ],
   "source": [
    "sys_msg = \"\"\"\n",
    "You are a JUDGE agent implemented using LangGraph.\n",
    "\n",
    "Your role is to receive the outputs of TWO previous agents:\n",
    "1) A WITH-TOOLS agent\n",
    "2) A NO-TOOLS agent\n",
    "\n",
    "You MUST run both agents, analyze their outputs, explain the differences\n",
    "between their solutions, and then write a short summary.\n",
    "\n",
    "====================\n",
    "MANDATORY TOOL CALLS\n",
    "====================\n",
    "You MUST do the following in order:\n",
    "\n",
    "1) Call ask_agent_with_tools(start_blocks, goal_blocks) EXACTLY ONCE.\n",
    "2) Call ask_agent_without_tools(start_blocks, goal_blocks) EXACTLY ONCE.\n",
    "\n",
    "Do NOT skip any call.\n",
    "Do NOT retry tools.\n",
    "\n",
    "====================\n",
    "ANALYSIS TASK\n",
    "====================\n",
    "After receiving BOTH outputs:\n",
    "\n",
    "- Compare the two solutions.\n",
    "- Explain the differences between them, such as:\n",
    "  * Use of tools vs. reasoning without tools\n",
    "  * Reliability and optimality of the solution\n",
    "  * Clarity and correctness of the result\n",
    "- Do NOT recompute the solution yourself.\n",
    "- Base your explanation ONLY on the agents’ outputs.\n",
    "\n",
    "====================\n",
    "OUTPUT REQUIREMENTS\n",
    "====================\n",
    "Write a SHORT, CLEAR explanation in plain English that includes:\n",
    "\n",
    "1) A comparison of the two agents’ solutions\n",
    "2) An explanation of the key differences\n",
    "3) A brief concluding summary\n",
    "\n",
    "You are NOT required to output numeric costs or choose a winner unless it\n",
    "naturally follows from your explanation.\n",
    "\n",
    "====================\n",
    "PROHIBITED\n",
    "====================\n",
    "- Do NOT solve the puzzle yourself\n",
    "- Do NOT invent results\n",
    "- Do NOT ignore either agent’s output\n",
    "- Do NOT call any tool more than once\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_cases = [\n",
    "    (\"(5,2),(1,3),(9,22),(21,4)\", \"2,22,4,3\"),\n",
    "    (\"(1,2),(3,4),(5,6),(7,8)\", \"7,5,3,1\"),\n",
    "    (\"(1,2),(3,4),(5,6),(7,8)\", \"3,7,1,5\"),\n",
    "    (\"(10,1),(2,20),(3,30),(4,40)\", \"4,10,3,2\"),\n",
    "    (\"(8,9),(7,6),(5,4),(3,2)\", \"7,3,8,5\"),\n",
    "]\n",
    "\n",
    "for i, (start_blocks, goal_blocks) in enumerate(test_cases, 1):\n",
    "    print(f\"\\n================= CASE {i} =================\")\n",
    "\n",
    "    judge_prompt = f\"\"\"\n",
    "Instance:\n",
    "start_blocks = \"{start_blocks}\"\n",
    "goal_blocks  = \"{goal_blocks}\"\n",
    "\"\"\"\n",
    "\n",
    "    tool_list = [ask_with_tools_tool, ask_without_tools_tool]\n",
    "    response, tools_used, outputs = await run_agent(judge_prompt, tool_list, sys_msg)\n",
    "\n",
    "    print(\"=== RESPONSE ===\")\n",
    "    print(response)\n",
    "    print(\"=== TOOLS USED ===\")\n",
    "    print(tools_used)\n",
    "    print(\"=== TOOL OUTPUTS ===\")\n",
    "    print(outputs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
