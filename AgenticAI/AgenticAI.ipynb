{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88079a16",
   "metadata": {},
   "source": [
    "# Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ae079",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8d156",
   "metadata": {},
   "source": [
    "### Install a Local LLM with Ollama\n",
    "\n",
    "To run this project locally, we will install and use **Ollama**, a lightweight runtime for local large language models.\n",
    "\n",
    "**Download Ollama:**  \n",
    "https://ollama.com/\n",
    "\n",
    "Once installed, you can pull any model you want to run.  \n",
    "Below are a few recommended examples, but you are free to pick any size or model from the Ollama library.\n",
    "\n",
    "ollama pull qwen3:0.6b\n",
    "\n",
    "or\n",
    "\n",
    "ollama pull ibm/granite4:350m\n",
    "\n",
    "or\n",
    "\n",
    "Choose any model you prefer, make sure the model supports tools.\n",
    "Browse available models here:\n",
    "https://ollama.com/library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42933887",
   "metadata": {},
   "source": [
    "### Python requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e73d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langgraph langchain-google-genai langchain-core mcp langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e2139",
   "metadata": {},
   "source": [
    "## 1. Define FastMCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad28890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristics import *\n",
    "from color_blocks_state import *\n",
    "from search import *\n",
    "import asyncio\n",
    "from langchain_core.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f2c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "\n",
    "def normalize_start_blocks_any(x: Any) -> str:\n",
    "    \"\"\"\n",
    "    Returns canonical \"(a,b),(c,d),...\" string.\n",
    "    Accepts:\n",
    "      - str: \"(5,2),(1,3)...\"\n",
    "      - list[str] chunks\n",
    "      - list[tuple[int,int]] or tuple[tuple[int,int],...]\n",
    "    \"\"\"\n",
    "    # tuple/list of pairs -> convert directly\n",
    "    if isinstance(x, (list, tuple)) and x and all(isinstance(t, (list, tuple)) and len(t) == 2 for t in x):\n",
    "        pairs = [f\"({int(a)},{int(b)})\" for a, b in x]\n",
    "        return \",\".join(pairs)\n",
    "\n",
    "    # list of strings -> join\n",
    "    if isinstance(x, list):\n",
    "        s = \",\".join(str(p) for p in x)\n",
    "    else:\n",
    "        s = str(x)\n",
    "\n",
    "    s = s.strip().lstrip(\"/\").strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    # extract (d,d) pairs\n",
    "    pairs = re.findall(r\"\\(\\s*\\d+\\s*,\\s*\\d+\\s*\\)\", s)\n",
    "    if not pairs:\n",
    "        raise ValueError(f\"start_blocks invalid: expected '(a,b),(c,d),...' got {x!r}\")\n",
    "    return \",\".join(p.replace(\" \", \"\") for p in pairs)\n",
    "\n",
    "\n",
    "def normalize_goal_blocks_any(x: Any) -> str:\n",
    "    \"\"\"\n",
    "    Normalize goal_blocks into canonical \"a,b,c,...\" string.\n",
    "\n",
    "    Accepts artifacts like:\n",
    "      - \"/10,2,3,4\"\n",
    "      - \"/2,/4,/6,/8\"   <-- per-token slashes\n",
    "      - quotes, spaces\n",
    "      - list/tuple of ints/strings\n",
    "    \"\"\"\n",
    "    # list/tuple of ints or digit-strings -> join\n",
    "    if isinstance(x, (list, tuple)) and x and all(\n",
    "        isinstance(v, int) or (isinstance(v, str) and v.strip().lstrip(\"/\").isdigit())\n",
    "        for v in x\n",
    "    ):\n",
    "        return \",\".join(str(int(str(v).strip().lstrip(\"/\"))) for v in x)\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # strip wrappers/quotes\n",
    "    s = s.strip('\"').strip(\"'\")\n",
    "    s = s.replace(\" \", \"\")\n",
    "\n",
    "    # If it looks like weird nested tuples, reject clearly\n",
    "    if s.startswith(\"[(\") or s.startswith(\"((\"):\n",
    "        raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "\n",
    "    # split by comma, strip leading '/' from EACH token\n",
    "    tokens = [t for t in s.split(\",\") if t != \"\"]\n",
    "    cleaned = []\n",
    "    for t in tokens:\n",
    "        t2 = t.strip().lstrip(\"/\")   # <-- key fix\n",
    "        if not t2.isdigit():\n",
    "            raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "        cleaned.append(t2)\n",
    "\n",
    "    if not cleaned:\n",
    "        raise ValueError(f\"goal_blocks invalid: expected 'a,b,c,...' got {x!r}\")\n",
    "\n",
    "    return \",\".join(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3eeb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.server.fastmcp import FastMCP\n",
    "import math\n",
    "\n",
    "# Initialize FastMCP\n",
    "mcp = FastMCP(\"Unified Solver\")\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_sum(a: float, b: float) -> float:\n",
    "    \"\"\"Calculates the sum of two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Calculates the power of a base number.\"\"\"\n",
    "    return math.pow(base, exponent)\n",
    "\n",
    "# TO DO: Add more tools as needed for your application\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def solve_cost_mcp(start_blocks, goal_blocks) -> float:\n",
    "    \"\"\"\n",
    "    Compute the optimal solution cost for the Color Blocks search problem.\n",
    "\n",
    "    INPUTS (MUST be single values, not nested objects):\n",
    "    - start_blocks: string \"(a,b),(c,d),...\"  (each block is a pair top,bottom)\n",
    "    - goal_blocks:  string \"g0,g1,g2,...\" (top colors required at each position)\n",
    "\n",
    "    OUTPUT:\n",
    "    - A single number (float): optimal path cost (each move costs 1).\n",
    "    \"\"\"\n",
    "    start_blocks = normalize_start_blocks_any(start_blocks)\n",
    "    goal_blocks  = normalize_goal_blocks_any(goal_blocks)\n",
    "\n",
    "    init_goal_for_heuristics(goal_blocks)\n",
    "    init_goal_for_search(goal_blocks)\n",
    "    start_state = color_blocks_state(blocks_str=start_blocks)\n",
    "    path = search(start_state, advanced_heuristic)\n",
    "    return float(\"inf\") if path is None else float(path[-1].g)\n",
    "\n",
    "def solve_cost_wrapper(start_blocks: str, goal_blocks: str) -> float:\n",
    "    # Just delegate to your MCP tool function\n",
    "    return solve_cost_mcp(start_blocks, goal_blocks)\n",
    "\n",
    "\n",
    "def as_langchain_tool_from_fn(fn, name: str, description: str):\n",
    "    return StructuredTool.from_function(\n",
    "        func=fn,\n",
    "        name=name,\n",
    "        description=description,\n",
    "        coroutine=fn if asyncio.iscoroutinefunction(fn) else None,\n",
    "    )\n",
    "\n",
    "\n",
    "solve_cost_tool = as_langchain_tool_from_fn(\n",
    "    solve_cost_wrapper,\n",
    "    name=\"solve_color_blocks_cost\",\n",
    "    description=\"\"\"\n",
    "    Compute the optimal solution cost for the Color Blocks search problem.\n",
    "\n",
    "    INPUTS (MUST be single values, not nested objects):\n",
    "    - start_blocks: string \"(a,b),(c,d),...\"  (each block is a pair top,bottom)\n",
    "    - goal_blocks:  string \"g0,g1,g2,...\" (top colors required at each position)\n",
    "\n",
    "    OUTPUT:\n",
    "    - A single number (float): optimal path cost (each move costs 1).\n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32e06d",
   "metadata": {},
   "source": [
    "## 2. LLM + MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e9ea7",
   "metadata": {},
   "source": [
    "### 2.1. Global instance of our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# Local for agents (cheap)\n",
    "agent_llm = ChatOllama(model=\"qwen2.5:7b-instruct\", temperature=0)  # or any local model you have\n",
    "\n",
    "# Gemini only for judge (1 call / case)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAXzRnKboS9glnL2UkNpOY2kFd3fQFW5ZQ\"\n",
    "judge_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d5dee",
   "metadata": {},
   "source": [
    "### 2.2. Our agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver # Optional: For saving graph state\n",
    "\n",
    "\n",
    "def create_agent_graph(sys_msg, tools, llm):\n",
    "    llm_with_tools = llm.bind_tools(tools) if tools else llm\n",
    "\n",
    "    def assistant(state: MessagesState):\n",
    "        return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"assistant\", assistant)\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "\n",
    "    if tools:\n",
    "        builder.add_node(\"tools\", ToolNode(tools))\n",
    "        builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "        builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    return builder.compile()\n",
    "\n",
    "\n",
    "async def run_agent(prompt, tools, sys_msg=\"\", llm=None):\n",
    "    sys_msg = SystemMessage(content=sys_msg)\n",
    "    if llm is None:\n",
    "        llm = agent_llm  # default local\n",
    "\n",
    "    graph = create_agent_graph(sys_msg, tools, llm=llm)\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    result = await graph.ainvoke({\"messages\": [HumanMessage(content=prompt)]}, config)\n",
    "\n",
    "    last_msg = result[\"messages\"][-1].content\n",
    "\n",
    "    tools_used = []\n",
    "    tools_output = []\n",
    "    for msg in result[\"messages\"]:\n",
    "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "            for tool_call in msg.tool_calls:\n",
    "                tools_used.append(tool_call[\"name\"])\n",
    "        if msg.type == \"tool\":\n",
    "            tools_output.append(msg.content)\n",
    "\n",
    "    return last_msg, tools_used, tools_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73790d1f",
   "metadata": {},
   "source": [
    "### 2.3. Tools that run spacific agent (with tools and without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6678099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "import asyncio\n",
    "\n",
    "WITH_TOOLS_SYS = \"\"\"\n",
    "You are the WITH-TOOLS assistant.\n",
    "\n",
    "You MUST call the tool solve_cost_mcp EXACTLY ONCE using the given arguments.\n",
    "\n",
    "Input format (use EXACTLY as provided):\n",
    "- start_blocks: a single string in the format \"(a,b),(c,d),...\"\n",
    "- goal_blocks: a single string in the format \"x,y,z,...\"\n",
    "\n",
    "Rules:\n",
    "- Do NOT add or remove characters.\n",
    "- Do NOT add leading symbols (/, [, ], quotes).\n",
    "- Do NOT split start_blocks into a list.\n",
    "- Do NOT change the order of blocks.\n",
    "\n",
    "After the tool returns:\n",
    "- Output ONLY the numeric solution cost.\n",
    "- Do NOT include explanations or extra text.\n",
    "\"\"\"\n",
    "\n",
    "NO_TOOLS_SYS = \"\"\"\n",
    "You are the NO-TOOLS assistant.\n",
    "\n",
    "You are solving a SEARCH problem WITHOUT tools and WITHOUT running code.\n",
    "You must still produce an answer.\n",
    "\n",
    "Domain rules:\n",
    "- State is a list of pairs (top,bottom).\n",
    "- spin(i): swaps top and bottom of block i. Cost = 1.\n",
    "- flip(i): reverses the order of blocks from index i to the end. Cost = 1.\n",
    "- Goal: for each position i, the top color equals goal_blocks[i].\n",
    "\n",
    "Instructions:\n",
    "- Reason mentally using the rules above.\n",
    "- If unsure, prefer a CONSERVATIVE estimate (slightly higher, not lower).\n",
    "- Never refuse and never ask for more information.\n",
    "\n",
    "Output:\n",
    "- Output ONLY a single number representing the estimated solution cost.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_with_tools(start_blocks: str, goal_blocks: str) -> str:\n",
    "    \"\"\"\n",
    "    WITH-TOOLS assistant.\n",
    "    Must call solve_cost_mcp exactly once and return ONLY the numeric cost.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_msg = f\"\"\"{WITH_TOOLS_SYS}\n",
    "\n",
    "Use these exact inputs:\n",
    "start_blocks = \"{start_blocks}\"\n",
    "goal_blocks  = \"{goal_blocks}\"\n",
    "\"\"\"\n",
    "\n",
    "    # Only the solver tool is available\n",
    "    tools = [solve_cost_mcp]\n",
    "\n",
    "    last_msg, _, _ = await run_agent(\n",
    "        prompt=\"Compute the solution cost.\",\n",
    "        tools=tools,\n",
    "        sys_msg=sys_msg\n",
    "    )\n",
    "\n",
    "    return last_msg\n",
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_without_tools(start_blocks: str, goal_blocks: str) -> str:\n",
    "    \"\"\"\n",
    "    NO-TOOLS assistant.\n",
    "    Must estimate and return ONLY a numeric cost.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_msg = f\"\"\"{NO_TOOLS_SYS}\n",
    "\n",
    "Start blocks: {start_blocks}\n",
    "Goal blocks: {goal_blocks}\n",
    "\"\"\"\n",
    "\n",
    "    last_msg, _, _ = await run_agent(\n",
    "        prompt=\"Estimate the minimal solution cost. Output only a number.\",\n",
    "        tools=[],\n",
    "        sys_msg=sys_msg\n",
    "    )\n",
    "\n",
    "    return last_msg\n",
    "\n",
    "\n",
    "def as_langchain_tool(mcp_fn, *, name: str, description: str):\n",
    "    \"\"\"\n",
    "    Wrap an @mcp.tool() function (sync or async) as a LangChain tool\n",
    "    so it can be used inside LangGraph ToolNode.\n",
    "    \"\"\"\n",
    "    return StructuredTool.from_function(\n",
    "        func=mcp_fn,\n",
    "        name=name,\n",
    "        description=description,\n",
    "        coroutine=mcp_fn if asyncio.iscoroutinefunction(mcp_fn) else None,\n",
    "    )\n",
    "\n",
    "\n",
    "async def ask_with_tools_wrapper(start_blocks: str, goal_blocks: str) -> str:\n",
    "    return await ask_agent_with_tools(start_blocks, goal_blocks)\n",
    "\n",
    "async def ask_without_tools_wrapper(start_blocks: str, goal_blocks: str) -> str:\n",
    "    return await ask_agent_without_tools(start_blocks, goal_blocks)\n",
    "\n",
    "ask_with_tools_tool = as_langchain_tool(\n",
    "    ask_with_tools_wrapper,\n",
    "    name=\"ask_agent_with_tools\",\n",
    "    description=(\n",
    "        \"REQUIRES TWO STRING ARGS: start_blocks and goal_blocks. \"\n",
    "        \"Example: ask_agent_with_tools(start_blocks='(5,2),(1,3)', goal_blocks='2,22'). \"\n",
    "        \"Both must be provided; do not omit goal_blocks.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ask_without_tools_tool = as_langchain_tool(\n",
    "    ask_without_tools_wrapper,\n",
    "    name=\"ask_agent_without_tools\",\n",
    "    description=(\n",
    "        \"REQUIRES TWO STRING ARGS: start_blocks and goal_blocks. \"\n",
    "        \"Example: ask_agent_without_tools(start_blocks='(5,2),(1,3)', goal_blocks='2,22').\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f6ab0",
   "metadata": {},
   "source": [
    "## 3. Run the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ebf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= CASE 1 =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 503 Service Unavailable\"\n",
      "Retrying google.genai._api_client.BaseApiClient._request_once in 1.3374130368984094 seconds as it raised ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying google.genai._api_client.BaseApiClient._request_once in 2.9295035349909524 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 26.44794842s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying google.genai._api_client.BaseApiClient._request_once in 4.404809224219859 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 23.405209783s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying google.genai._api_client.BaseApiClient._request_once in 8.913220231929152 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 18.883453642s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying google.genai._api_client.BaseApiClient._request_once in 16.876824152220934 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 9.717043678s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 52.593477027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\models.py:5215\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5214\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5215\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5219\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\models.py:3997\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3995\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3997\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4002\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4003\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\_api_client.py:1375\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1372\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1373\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1374\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m response_body = (\n\u001b[32m   1377\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1378\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\_api_client.py:1209\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1208\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\_api_client.py:1188\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1181\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1182\u001b[39m     method=http_request.method,\n\u001b[32m   1183\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1187\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1190\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1191\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 52.593477027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     47\u001b[39m judge_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[33mYou MUST call BOTH tools with BOTH arguments.\u001b[39m\n\u001b[32m     49\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     59\u001b[39m tool_list = [ask_with_tools_tool, ask_without_tools_tool]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m response, tools_used, outputs = \u001b[38;5;28;01mawait\u001b[39;00m run_agent(judge_prompt, tool_list, sys_msg)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== RESPONSE ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(prompt, tools, sys_msg)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# 4. Run (using ainvoke for async tools)\u001b[39;00m\n\u001b[32m     53\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=prompt)]}, config=config)\n\u001b[32m     56\u001b[39m last_msg = result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Extract tool names and outputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\main.py:3161\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3158\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3159\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3161\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3162\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3163\u001b[39m     config,\n\u001b[32m   3164\u001b[39m     context=context,\n\u001b[32m   3165\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3168\u001b[39m     print_mode=print_mode,\n\u001b[32m   3169\u001b[39m     output_keys=output_keys,\n\u001b[32m   3170\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3171\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3172\u001b[39m     durability=durability,\n\u001b[32m   3173\u001b[39m     **kwargs,\n\u001b[32m   3174\u001b[39m ):\n\u001b[32m   3175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3176\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\main.py:2974\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2972\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2973\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2974\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2975\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2976\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2977\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2978\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2979\u001b[39m ):\n\u001b[32m   2980\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2982\u001b[39m         stream_mode,\n\u001b[32m   2983\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2986\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2987\u001b[39m     ):\n\u001b[32m   2988\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:138\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    140\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:845\u001b[39m, in \u001b[36mToolNode._afunc\u001b[39m\u001b[34m(self, input, config, runtime)\u001b[39m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m call, tool_runtime \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tool_calls, tool_runtimes, strict=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    844\u001b[39m     coros.append(\u001b[38;5;28mself\u001b[39m._arun_one(call, input_type, tool_runtime))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m outputs = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*coros)\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combine_tool_outputs(outputs, input_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1176\u001b[39m, in \u001b[36mToolNode._arun_one\u001b[39m\u001b[34m(self, call, input_type, tool_runtime)\u001b[39m\n\u001b[32m   1172\u001b[39m config = tool_runtime.config\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._awrap_tool_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_tool_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1175\u001b[39m     \u001b[38;5;66;03m# No wrapper - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._execute_tool_async(tool_request, input_type, config)\n\u001b[32m   1178\u001b[39m \u001b[38;5;66;03m# Define async execute callable that can be called multiple times\u001b[39;00m\n\u001b[32m   1179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(req: ToolCallRequest) -> ToolMessage | Command:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1125\u001b[39m, in \u001b[36mToolNode._execute_tool_async\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m   1122\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;66;03m# Error is handled - create error ToolMessage\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m     content = \u001b[43m_handle_tool_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_tool_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[32m   1127\u001b[39m         content=content,\n\u001b[32m   1128\u001b[39m         name=call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1129\u001b[39m         tool_call_id=call[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1130\u001b[39m         status=\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1131\u001b[39m     )\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# Process successful response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:429\u001b[39m, in \u001b[36m_handle_tool_error\u001b[39m\u001b[34m(e, flag)\u001b[39m\n\u001b[32m    427\u001b[39m     content = flag\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(flag):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     content = \u001b[43mflag\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [assignment, call-arg]\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    431\u001b[39m     msg = (\n\u001b[32m    432\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected type of `handle_tool_error`. Expected bool, str \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    433\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mor callable. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    434\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:386\u001b[39m, in \u001b[36m_default_handle_tool_errors\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ToolInvocationError):\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e.message\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1082\u001b[39m, in \u001b[36mToolNode._execute_tool_async\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1082\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m tool.ainvoke(call_args, config)\n\u001b[32m   1083\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1084\u001b[39m         \u001b[38;5;66;03m# Filter out errors for injected arguments\u001b[39;00m\n\u001b[32m   1085\u001b[39m         injected = \u001b[38;5;28mself\u001b[39m._injected_args.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\tools\\structured.py:67\u001b[39m, in \u001b[36mStructuredTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine:\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# If the tool does not implement async, fall back to default implementation\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(config, \u001b[38;5;28mself\u001b[39m.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\tools\\base.py:642\u001b[39m, in \u001b[36mBaseTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    636\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    639\u001b[39m     **kwargs: Any,\n\u001b[32m    640\u001b[39m ) -> Any:\n\u001b[32m    641\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.arun(tool_input, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\tools\\base.py:1117\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_error(error_to_raise)\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m   1119\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\tools\\base.py:1083\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m   1080\u001b[39m         tool_kwargs[config_param] = config\n\u001b[32m   1082\u001b[39m     coro = \u001b[38;5;28mself\u001b[39m._arun(*tool_args, **tool_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(coro, context)\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1085\u001b[39m     msg = (\n\u001b[32m   1086\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSince response_format=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1087\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33ma two-tuple of the message content and raw tool output is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1088\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected. Instead, generated response is of type: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1089\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1090\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\tools\\structured.py:121\u001b[39m, in \u001b[36mStructuredTool._arun\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.coroutine):\n\u001b[32m    120\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine(*args, **kwargs)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# If self.coroutine is None, then this will delegate to the default\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# implementation which is expected to delegate to _run on a separate thread.\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._arun(\n\u001b[32m    126\u001b[39m     *args, config=config, run_manager=run_manager, **kwargs\n\u001b[32m    127\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mask_without_tools_wrapper\u001b[39m\u001b[34m(start_blocks, goal_blocks)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mask_without_tools_wrapper\u001b[39m(start_blocks: \u001b[38;5;28mstr\u001b[39m, goal_blocks: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ask_agent_without_tools(start_blocks, goal_blocks)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mask_agent_without_tools\u001b[39m\u001b[34m(start_blocks, goal_blocks)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    NO-TOOLS assistant.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[33;03m    Must estimate and return ONLY a numeric cost.\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m     sys_msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNO_TOOLS_SYS\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[33mStart blocks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_blocks\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33mGoal blocks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgoal_blocks\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     last_msg, _, _ = \u001b[38;5;28;01mawait\u001b[39;00m run_agent(\n\u001b[32m     85\u001b[39m         prompt=\u001b[33m\"\u001b[39m\u001b[33mEstimate the minimal solution cost. Output only a number.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m         tools=[],\n\u001b[32m     87\u001b[39m         sys_msg=sys_msg\n\u001b[32m     88\u001b[39m     )\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m last_msg\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(prompt, tools, sys_msg)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# 4. Run (using ainvoke for async tools)\u001b[39;00m\n\u001b[32m     53\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=prompt)]}, config=config)\n\u001b[32m     56\u001b[39m last_msg = result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Extract tool names and outputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\main.py:3161\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3158\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3159\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3161\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3162\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3163\u001b[39m     config,\n\u001b[32m   3164\u001b[39m     context=context,\n\u001b[32m   3165\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3168\u001b[39m     print_mode=print_mode,\n\u001b[32m   3169\u001b[39m     output_keys=output_keys,\n\u001b[32m   3170\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3171\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3172\u001b[39m     durability=durability,\n\u001b[32m   3173\u001b[39m     **kwargs,\n\u001b[32m   3174\u001b[39m ):\n\u001b[32m   3175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3176\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\main.py:2974\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2972\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2973\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2974\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2975\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2976\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2977\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2978\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2979\u001b[39m ):\n\u001b[32m   2980\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2982\u001b[39m         stream_mode,\n\u001b[32m   2983\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2986\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2987\u001b[39m     ):\n\u001b[32m   2988\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:138\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    140\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\runnables\\config.py:610\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    609\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    611\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    612\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[..., T]\u001b[39m\u001b[33m\"\u001b[39m, partial(copy_context().run, wrapper)),\n\u001b[32m    613\u001b[39m     )\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\runnables\\config.py:601\u001b[39m, in \u001b[36mrun_in_executor.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m() -> T:\n\u001b[32m    600\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    603\u001b[39m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[32m    604\u001b[39m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[32m    605\u001b[39m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[32m    606\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcreate_agent_graph.<locals>.assistant\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massistant\u001b[39m(state: MessagesState):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m             \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys_msg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m         ]\n\u001b[32m     23\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\AI4\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 52.593477027s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
      "During task with name 'assistant' and id '970bfbd6-dd50-6719-a32b-587b561de175'",
      "During task with name 'tools' and id '8afa50a3-01e3-07d5-c175-511aab2ed759'"
     ]
    }
   ],
   "source": [
    "sys_msg = \"\"\"\n",
    "You are a judge comparing two assistants on the SAME Color Blocks instance.\n",
    "\n",
    "You MUST:\n",
    "1) Call ask_agent_with_tools(start_blocks, goal_blocks) exactly once.\n",
    "2) Call ask_agent_without_tools(start_blocks, goal_blocks) exactly once.\n",
    "3) For each result, determine if it SUCCEEDED:\n",
    "   - Succeeded if the returned text contains a valid finite number.\n",
    "   - Failed if it contains an error message (e.g., 'Error invoking tool', 'Field required') OR no number OR NaN/inf.\n",
    "\n",
    "Decision rule (\"Better\"):\n",
    "Lower cost is better. But with good reasoning:\n",
    "- If one succeeded and the other failed, the succeeded one is better.\n",
    "- If both succeeded, the lower cost is better.\n",
    "- If both failed, pick either but explain both failed.\n",
    "- the agent with tools is more accurate in general.\n",
    "\n",
    "You must use both tool based and no-tools results to decide and call those agents.\n",
    "\n",
    "You must use this EXACT format:\n",
    "Tool-based cost: <number-or-NA>\n",
    "No-tools cost: <number-or-NA>\n",
    "Better: <tool-based or no-tools>\n",
    "Reason: <one short sentence>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "test_cases = [\n",
    "    # Classic from your example (non-trivial, known cost 6 in your run)\n",
    "    (\"(5,2),(1,3),(9,22),(21,4)\", \"2,22,4,3\"),\n",
    "\n",
    "    # # Reverse goal forces flips (tops are 1,3,5,7 but goal is reversed)\n",
    "    # (\"(1,2),(3,4),(5,6),(7,8)\", \"7,5,3,1\"),\n",
    "\n",
    "    # # Mixed permutation (not just reverse)\n",
    "    # (\"(1,2),(3,4),(5,6),(7,8)\", \"3,7,1,5\"),\n",
    "\n",
    "    # # Another mixed permutation with bigger numbers\n",
    "    # (\"(10,1),(2,20),(3,30),(4,40)\", \"4,10,3,2\"),\n",
    "\n",
    "    # # Tops are 8,7,5,3 but goal permuted\n",
    "    # (\"(8,9),(7,6),(5,4),(3,2)\", \"7,3,8,5\"),\n",
    "]\n",
    "\n",
    "for i, (start_blocks, goal_blocks) in enumerate(test_cases, 1):\n",
    "    print(f\"\\n================= CASE {i} =================\")\n",
    "\n",
    "    tool_out = await ask_agent_with_tools(start_blocks, goal_blocks)        # local\n",
    "    no_tool_out = await ask_agent_without_tools(start_blocks, goal_blocks)  # local\n",
    "\n",
    "    judge_prompt = f\"\"\"\n",
    "tool_based_output:\n",
    "{tool_out}\n",
    "\n",
    "no_tools_output:\n",
    "{no_tool_out}\n",
    "\n",
    "Output EXACTLY 4 lines:\n",
    "Tool-based cost: <number-or-NA>\n",
    "No-tools cost: <number-or-NA>\n",
    "Better: <tool-based or no-tools>\n",
    "Reason: <one short sentence>\n",
    "\"\"\"\n",
    "\n",
    "    response, _, _ = await run_agent(judge_prompt, tools=[], sys_msg=sys_msg, llm=judge_llm)\n",
    "    print(response)\n",
    "\n",
    "    print(\"=== RESPONSE ===\")\n",
    "    print(response)\n",
    "    print(\"=== TOOLS USED ===\")\n",
    "    print(tools_used)\n",
    "    print(\"=== TOOL OUTPUTS ===\")\n",
    "    print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
